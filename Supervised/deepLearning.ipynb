{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"AMZN\", \"TSLA\", \"BABA\", \"HD\", \"TM\", \"NKE\", \"MCD\", \"LOW\", \"SBUX\", \"JD\", \"PDD\", \"BKNG\", \"GM\", \"MELI\", \"TJX\", \"NIO\", \"F\", \"LULU\", \"HMC\", \"CMG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "\n",
    "\n",
    "    thresh = cm.numpy().max() / 1.5 if normalize else cm.numpy().max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig(\"./deep_learning_plots/\" + title + '.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title1, title2):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(\"./deep_learning_plots/\" + title1 + '.png')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(\"./deep_learning_plots/\" + title2 + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us try to train on a simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_dim=14))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    # model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'mse'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = pd.read_csv(f'./data_with_labels/{ticker}_with_labels.csv')\n",
    "    features, labels = data.drop(['policy', 'Date'], axis=1).to_numpy(), data['policy'].to_numpy()\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True)\n",
    "    enc_ytrain_labels = enc.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "    enc_ytest_labels = enc.fit_transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "    \n",
    "    model = create_model(shape = X_train.shape)\n",
    "    history = model.fit(X_train, enc_ytrain_labels, epochs=150, batch_size=16, verbose=1, validation_data=(X_test, enc_ytest_labels))\n",
    "    \n",
    "    loss, accuracy, mse = model.evaluate(X_test, enc_ytest_labels, batch_size=16, verbose=1)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    print(f\"Confusion Matrix for {ticker}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, np.arange(4), title=f\"NN Confusion Matrix for {ticker} Dense\")\n",
    "\n",
    "    plot_history(history, f\"NN Accuracy for {ticker} Dense\", f\"NN Loss for {ticker} Dense\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's try a more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_data_transform(x_data, y_data, num_steps=5):\n",
    "    \"\"\" Changes data to the format for LSTM training \n",
    "    for sliding window approach \"\"\"\n",
    "    # Prepare the list for the transformed data\n",
    "    X, y = list(), list()\n",
    "    # Loop of the entire data set\n",
    "    for i in range(x_data.shape[0]):\n",
    "        # compute a new (sliding window) index\n",
    "        end_ix = i + num_steps\n",
    "        # if index is larger than the size of the dataset, we stop\n",
    "        if end_ix >= x_data.shape[0]:\n",
    "            break\n",
    "        # Get a sequence of data for x\n",
    "        seq_X = x_data[i:end_ix]\n",
    "        # Get only the last element of the sequency for y\n",
    "        seq_y = y_data[end_ix]\n",
    "        # Append the list with sequencies\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "    # Make final arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array\n",
    "    \n",
    "def create_model_LSTM(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(16, activation='tanh'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy', 'mse'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "\n",
    "random_tickers_to_train_on = np.random.choice(tickers, size=5, replace=False)\n",
    "\n",
    "\n",
    "for ticker in random_tickers_to_train_on:\n",
    "    data = pd.read_csv(f'./data_with_labels/{ticker}_with_labels.csv')\n",
    "    features, labels = data.drop(['policy', 'Date'], axis=1), data['policy']\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    features, labels = lstm_data_transform(features, labels)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True)\n",
    "    enc_ytrain_labels = enc.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "    enc_ytest_labels = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "    \n",
    "    model = create_model_LSTM(shape = X_train.shape)\n",
    "    history = model.fit(X_train, enc_ytrain_labels, epochs=20, batch_size=32, verbose=1,  validation_data=(X_test, enc_ytest_labels))\n",
    "\n",
    "\n",
    "    loss, accuracy, mse = model.evaluate(X_test, enc_ytest_labels, batch_size=16, verbose=1)\n",
    "    \n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    print(f\"Confusion Matrix for {ticker}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, np.arange(4), title=f\"NN Confusion Matrix for {ticker} LSTM\")\n",
    "\n",
    "    plot_history(history, f\"NN Accuracy for {ticker} LSTM\", f\"NN Loss for {ticker} LSTM\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "476bfb384926c7d81c906196e2e08fe7166f80aae65bf13e991244f224c6b1aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml_proj': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
